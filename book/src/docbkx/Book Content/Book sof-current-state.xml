<?xml version="1.0" encoding="UTF-8"?>
<?xml-model href="http://docbook.org/xml/5.1/rng/docbook.rng" schematypens="http://relaxng.org/ns/structure/1.0"?>
<?xml-model href="http://docbook.org/xml/5.1/sch/docbook.sch" type="application/xml" schematypens="http://purl.oclc.org/dsdl/schematron"?>
<chapter xmlns="http://docbook.org/ns/docbook"
    xmlns:xlink="http://www.w3.org/1999/xlink" version="5.1">
    <title>Current State of Real World Evidence (RWE) Analytics</title>
         
    
    <section>
        <title>Real World Data (RWD) and RWE Overview</title>
        <para>RWD is defined as data relating to patient health status and/or the delivery of health
            care collected from a variety of sources during routine care or daily living. It
            encompasses most sources of health data derived from common sources such as traditional
            clinical trial settings, including EHRs, claims and billing activities, disease
            registries, pharmacy records, as well as non-standard sources such as social media and
            wearable devices. [41] </para>
        <para>Large quantities of clinical data are generated throughout the various stages of an
            individual’s health care journey. When a patient visits a care provider, has their
            vitals recorded, reports their symptoms, undergoes laboratory tests, receives a
            prescription, or submits an insurance claim, valuable clinical data is created at each
            step. The data from each individual stage is stored in a variety of ways. Some data is
            discrete in nature, some is encoded, and still other data is recorded using natural
            language or text. In addition, data collected is contained within a siloed data
            ecosystem based on software system specific parameters that are different from other
            systems. Though information can be shared between entities to facilitate care from step
            to step, aggregation and standardization is difficult to reliably perform meaningful
            analytics without substantial data curation efforts. </para>
        <para>Similar to RWD, RWE is defined as clinical evidence about the usage and potential
            benefits, or risks of medical treatments, technologies, drugs, or interventions derived
            from sources other than clinical trials. [42] It refers to analysis of data that has
            been collected outside the traditional randomized clinical trial (RCT) setting. RWE has
            immense value in advancing medical research, particularly when deriving the required
            information in a clinical trial would be unfeasible or unethical. [43]. By design, RWD
            and RWE are generated independent of a specific research question or study design and
            must be aggregated. This can be a benefit in some cases and a barrier in others.
            Aggregating RWD across multiple sites is necessary to establish sufficient
            representation of the study and control cohorts but is difficult due to data
            interoperability barriers. </para>
        
    </section>
    <section>
        <title>RWD Applications and Limitations</title>
        <para>Despite significant challenges, RWD and RWE present immense untapped potential within
            public health, research, safety and regulation, and post-market surveillance. A variety
            of health care entities have taken interest in RWD in recent years, including federal
            agencies, pharmaceutical companies, medical device manufacturers, and patients. One of
            the primary applications of RWE thus far has been in post-market surveillance monitoring
            drug safety and efficacy as well as researching health outcomes that are difficult to
            study with traditional methods, such as with lesser understood conditions, smaller
            patient populations, and long follow-up periods. [43] However, during the COVID-19
            pandemic, RWD served as the primary source of information available to the medical
            community to understand COVID and evaluate the safety and efficacy of IVD testing,
            antigen testing, and vaccinations. As an example, the State of Nebraska Department of
            Epidemiology and the Nebraska Public Health Laboratory operated large numbers of
            specimen collection centers for COVID testing. Each patient was required to report
            symptom status for loss of smell or taste prior to testing by antigen or polymerase
            chain reaction (PCR). Analysis showed that the presence of one or both symptoms had a
            positive predictive value (PPV) of 80% for COVID. These RWD provided the RWE to support
            pool testing of specimens to conserve testing reagents during a period of severe test
            supply shortages. [44] </para>
        <para>The use of RWD that is of sufficient quality to be used as RWE for market approval,
            post-market surveillance of medicines, and in IVD presents a potentially rich
            environment and supplement to the current gold-standard controlled clinical trial
            methodologies. To this effect, Congress signed the 21st Century Cures Act (Cures Act)
            into law in 2016 to help accelerate the development of medical products and bring new
            innovations to patient populations. [41] The law intends to increase federal focus on
            evaluating RWD and RWE for regulatory decision making for new approvals, support
            post-approval study requirements, and evaluate additional indications for approved
            treatments. [41]</para>
        <para>Unfortunately, RWD and RWE face numerous obstacles that hinder their reliable
            widespread use ranging from data quality and bias, lack of standardization, data access
            challenges, and privacy concerns. One of the most significant challenges is that of data
            interoperability. The movement of a Portable Document Format (PDF) medical report from
            Institution A to Institution B is done routinely, but none of the data held within the
            report is computable, and thus is not interoperable. Discrete EHR data can be computable
            within its source system but cannot be electronically exchanged to a second institution
            and reliably and safely computed to convey the exact same meaning as initially intended
            because these data, even data between identical EHR systems, do not carry sufficient
            context to convey appropriate meaning to be safely and reliably reconstructed between
            system instances. Finally, data encoded using standardized medical terminology, such as
            laboratory data, that is electronically exchanged and computable between systems does
            not safely guarantee the data will be considered to have the exact same meaning between
            systems. [45] Such a gap in surveillance, data capture, data exchange, data
            harmonization, and subsequent analytics place the U.S. at risk to repeat the 'data
            scramble' in the event of another emerging disease, as experienced during COVID. To
            realize the potential of RWD which is suitable as RWE for regulatory, research, public
            health, and clinical care purposes, data interoperability must be achieved. </para>
        <section>
            <title>Current RWD Uses</title>
            <para>There are several national and international efforts to aggregate and expose
                EHR/RWD for use by researchers and public health scientists. Such efforts include
                the National Patient-Centered Clinical Research Network (PCORnet), Observational
                Health Data Sciences and Informatics (OHDSI), National COVID Cohort Collaborative
                (N3C) and its potential spin offs. Common to each of these efforts is the extraction
                of EHR data from participating entities, transforming these data to a common data
                model, annotating/managing the data with standardized medical terminologies and
                aggregating entities’ datasets in consolidated or federated mechanisms for analyses. </para>
            <section>
                <title>National Covid Cohort Collaborative (N3C)</title>
                <para>N3C is one of the largest cloud-based collections of secure and de-identified
                    COVID-19 clinical data. N3C aims to harmonize EHR data into a common data model
                    to enhance research and clinical access to reliable COVID-19 data, generate
                    novel approaches to better understand and address the impact of COVID-19, and
                    mitigate future pandemics. The National Center for Advancing Translational
                    Sciences (NCATS) N3C Data Enclave contains RWD from contributing sites’ EHR
                    systems with COVID-19 positive patients and patients with symptoms consistent
                    with COVID-19, Severe acute respiratory syndrome coronavirus 1 (SARS 1), Middle
                    East Respiratory Syndrome (MERS), and H1N1 flu (a.k.a. Swine flu). De-identified
                    data is contributed monthly and augmented by public health laboratory data and
                    whole genome sequence data of paired patient/specimen isolates. </para>
                <para>N3C has paved the way as a successful model for other data enclaves. Data
                    codification is well described, and the data harmonization team ingests limited
                    data sets and transforms them according to a harmonized Observational Medical
                    Outcomes Partnership (OMOP) analytics data set. Data and code provenance are
                    tracked through the platform. Privacy Preserving Record Linkage (PPRL) is used
                    to securely connect records while maintaining the anonymity of an individual
                    across multiple records and may enhance COVID-19 RWD research in N3C through
                    de-duplication of patient records, linking patient records from different
                    sources, and cohort discovery. Organizations submitting data must have an
                    approved Data Transfer Agreement (DTA), and an optional Linkage Honest Broker
                    Agreement (LHBA), through which organizations maintain control over their data.
                    Data analyses must be performed within the platform and are supported through R,
                    Python, and Slate. R packages include SciPy and scikit-learn and are
                    pre-installed, and others can be added by contacting the data enclave support
                    team. Overall, the enclave provides a secure and focused space for research
                    collaboration and has proven its impact through hundreds of peer reviewed,
                    scientific publications. </para>
                <para>However, the N3C has limitations, including geographic restriction to the
                    U.S., inclusion of only patients with recorded COVID-19 positive tests, limited
                    RWD on non-COVID patients, security constraints that can impact data quality and
                    participation, and no method for testing data equivalence between sites.
                    [46]</para>
            </section>
            <section>
                <title>Patient-Centered Outcomes Research Institute (PCORI) and National
                    Patient-Centered Clinical Research Network (PCORnet)</title>
                <para>The Patient-Centered Outcomes Research Institute (PCORI) is an independent,
                    nonprofit, and leading funder of patient-centered comparative clinical
                    effectiveness research (CER) in the United States. Its primary goal is to
                    increases useful information, speed the uptake and use of information, and
                    influence funded research to be more patient centered. PCORI funded research,
                    which includes over 2,000 studies and related projects, provides healthcare
                    decision makers comparative data on medical treatments and encourages the
                    sharing of data sets and documentation to build on findings and generate new
                    evidence. PCORI approved $1 million in funding for the development of automated
                    ways to more efficiently and accurately identify patients with rare diseases via
                    EHR data, facilitating earlier treatments and research participation.
                    [47]</para>
                <para>In 2013, PCORI funded development of the PCORnet, a national resource for
                    health data and research expertise aimed at providing patient centered outcomes
                    research in a timely manner. [48] PCORnet is a well established and fully
                    integrated network that leverages EHR data and registries to expand the role of
                    patients and care providers in the research process and conduct research that is
                    inexpensive, faster, and more patient-centered in its design. [49] It includes a
                    distributed network of Clinical Research Networks (CRNs) drawn from millions of
                    EHRs, with links to patient-reported and payer data, creating a standardized
                    data set for large-scale research. The network comprises 251 institutions
                    organized into 61 data contributors, including 337 hospitals, 169,695
                    physicians, 3,564 primary care practices, 338 emergency departments, and 1,024
                    community clinics serving underserved populations [48-50].</para>
                <para>PCORnet provides access to the health records of 66 million patients for
                    observational studies, ensuring data quality through rigorous conformance,
                    completeness, plausibility, and persistence standards and a Common Data Model
                    that normalizes data across health systems. Data security is maintained by
                    protecting data behind network partners' firewalls, with queries and responses
                    controlled through a secure Distributed Research Network Portal. However, due to
                    this security approach, researchers receive answers to queries rather than
                    direct access to data, but the network's scope and embedded expertise make it a
                    powerful tool for answering clinical questions that impact patients' lives,
                    including studies on populations affected by Long COVID [47, 51].</para>
            </section>
            <section>
                <title>Observational Health Data Sciences and Informatics (OHDSI)</title>
                <para>Founded in 2014, the Observational Health Data Sciences and Informatics
                    (OHDSI) is an interdisciplinary collaborative focused on maximizing the value of
                    health data through large-scale analytics and a common data model. Its mission
                    is to improve health by empowering a community to collaboratively generate
                    evidence that promotes better health decisions and care. With over 3,000
                    contributors from various sectors and data representing 810 million unique
                    individuals, OHDSI benefits patients, providers, researchers, and larger
                    organizations (such as hospital systems and government agencies) with open
                    source solutions and products. [52]</para>
                <para>Since its founding, OHDSI has made significant progress, including creating a
                    federated database with patient records representing about 12 percent of the
                    world’s population, and has been referenced by the European Medicines Agency and
                    other policy makers as well as journals, including Journal of the American
                    Medical Association (JAMA). OHDSI currently operates 27 working groups, ranging
                    in topic from focus regions (Asia-Pacific and Latin America regions), specific
                    care areas (oncology, psychiatry), FHIR®, the OMOP Common Data Model (CDM), and
                    Natural Language Processing (NLP). In April 2022, OHDSI and SNOMED International
                    formalized a five-year collaborative agreement in which OHDSI and the associated
                    user communities will receive “comprehensive ontologies on specific healthcare
                    domains and content such as devices, social determinants of health, disease
                    severity scores and modifiers of cancers, as well as better concept definitions
                    and resolutions of composite concepts in large-scale observational research.”
                    While this is an enormous benefit to OHDSI, SNOMED International gains valuable
                    user data from interactions with their products. OHDSI also has an existing
                    agreement with HL7® to integrate FHIR® with the OMOP common data model in hopes
                    of improving abilities to track and share data in the healthcare and research
                    industries. Finally, OHDSI has developed products like the Health Analytics
                    Data-to-Evidence Suite (HADES) and ATLAS, which support population-level
                    estimations, patient-level predictions, design and execution of observational
                    analyses to generate RWE from patient level data, and more.[52, 53]</para>
                <para>Despite the various achievements, OHDSI faces obstacles such as the complexity
                    of using international data for federal regulatory applications and the
                    limitations of fully de-identified data, which can restrict analyses requiring
                    individual or timestamped data. The collaborative's data collection is
                    well-suited for evaluating trends and associations but has challenges when
                    assessing causation due to the lack of timestamping and longitudinal data. These
                    limitations demonstrate common sacrifices that are often made when prioritizing
                    data standardization and interoperability, especially when the privacy
                    requirements of medical data require a base level of manipulation to obscure
                    incoming data.</para>
            </section>
            <section>
                <title>Electronic Medical Records and Genomics (eMERGE)</title>
                <para>The Electronic Medical Records and Genomics (eMERGE) Network, funded by the
                    National Human Genome Research Institute (NHGRI), combines genetic data with
                    EHRs to support genomic medicine research. Established in 2007, eMERGE has grown
                    to develop 777 publications, discovered 68 phenotypes, and encompassed over
                    136,000 network participants. eMERGE conducts genome wide association studies
                    (GWAS) with EHRs to sequence patients’ genes, evaluate disease risk, return
                    actionable results and analytical tools to clinicians and patients to improve
                    clinical care, and contribute findings to patient EHRs. The network also
                    calculates disease risk with polygenic risk scores (PRS) and compares ICD-10
                    codes across sites to assess comparability of large populations taken from
                    different institutions, evaluate privacy concerns surrounding patient consent
                    and continuing genomic research, and identify optimal methods for the
                    development and cross-site deployment of algorithms to identify case and control
                    cohorts. [46, 54, 55]</para>
                <para>eMERGE has provided valuable insights into genomics research and effective
                    data analysis across various institutions. For instance, investigators found
                    projects had better outcomes when performed across the entire network or across
                    multiple versus within individual sites due to the larger population sizes and
                    added statistical power. For example, eMERGE’s expansion to include pediatric
                    sites in addition to the existing adult data was challenging but enabled
                    researchers to examine heritable diseases that presented in childhood and
                    continued into adulthood. This type of analysis would have been unfeasible for
                    one site alone. [56] While data quality is of paramount importance when
                    collaborating across multiple sites, eMERGE uses common definitions and coding
                    for phenotype variables being deposited into the database of Genotypes and
                    Phenotypes (dpGaP) to support effective Quality Assurance/Quality Control
                    (QA/QC) of data as it comes in. [57]</para>
                <para>The size, scope, diversity, and continued collection of eMERGE’s data allows
                    the network to develop and execute additional analyses and cost-effective
                    longitudinal genomic studies as data evolves and medical interpretations change.
                    [56] The ability to build upon existing data is particularly valuable in fields
                    where scientific understanding is still evolving, as with genomics and novel
                    diseases or treatments. Even with the challenges inherent with multi-site
                    collaboration, eMERGE has demonstrated that interoperability risk can be
                    mitigated to allow for robust and powerful analytics.</para>
                <para>Despite its successes, eMERGE faces challenges such as ensuring patient
                    privacy and consent, data interoperability, and maintaining data quality across
                    multiple sites. Proper de-identification is crucial at each phase of data
                    collection to protect patient privacy. Ethical questions also arise regarding
                    whether an individual’s original consent allows for the continued sharing of
                    data with the database of Genotypes and Phenotypes (dpGaP) or expanded research
                    into additional phenotypes. [54] Additionally, data completeness within EHRs is
                    not guaranteed and there are no established processes for the secure,
                    generalizable, and interoperable data exchange between different healthcare
                    systems or terminology standards. This issue is exacerbated by the ever-changing
                    knowledge and medical interpretations surrounding genomic data as any
                    interoperability solutions must remain flexible to keep up as the field evolves.
                    eMERGE addresses these challenges by developing practices and communicating
                    findings to the genomic research community, emphasizing the need for consensus
                    on data standards and harmonization to perform effective multi-site analytics.
                    [56]</para>
            </section>
            <section>
                <title>Sentinel</title>
                <para>The FDA launched the Sentinel Initiative to inform FDA decision-making using
                    RWE generated from a distributed data network, a common data model, curated RWD,
                    and flexible analytic tools help and develop new ways of evaluating the safety
                    of approved drugs, devices, and treatments in response to the FDA Amendments Act
                    (FDAAA) of 2007 that mandated the use of EHR to perform safety assessments more
                    effectively. [58, 59]</para>
                <para>Sentinel collects EHR data that covers approximately 700 million person-years
                    of longitudinal observation time, much of which comes from a network of over 170
                    inpatient facilities and some of the nation’s largest health insurance
                    providers, including Aetna, Anthem, Humana, and Kaiser Permanente. [57, 58] The
                    Sentinel System is not a data repository, but rather a distributed network in
                    which each data partner maintains ownership and operational control of their
                    data in a way that allows Sentinel access to select full-text medical records,
                    inpatient data, and lab results from the nation’s largest hospital network that
                    covers approximately five percent of inpatient care and over 10 billion pharmacy
                    and medication encounters. [57] Data is standardized into the Sentinel Common
                    Data Model (SCDM) format for efficient analysis across data sources and flexible
                    computer programs that can run routine queries and perform analyses to inform
                    FDA decision making, ranging from medication utilization patterns among patient
                    cohorts to evaluation of drug and device safety. </para>
                <para>The Sentinel System presents significant potential with respect to the
                    research, approval, and maintenance of medical treatments. The combination of
                    expansive standardized data and flexible analytics allows the FDA to generate
                    RWE and associated analytics rapidly and reliably with relative ease, all while
                    minimizing risk to patient privacy. The capabilities of the Sentinel System are
                    varied, including the ability to access full-text medical records, support RCTs,
                    and streamline the collection of patient data from mobile devices. [57] This
                    system has enhanced the FDA’s central purpose by allowing it to design and
                    execute post-market studies that would have previously been required of medical
                    product sponsors. [59] Similarly, the FDA maintains authority to mandate
                    companies perform post-approval studies when potential safety concerns arise,
                    and Sentinel could be used to drive those decisions. Sentinel’s Active Risk
                    Identification and Analysis (ARIA) System evaluates the safety of approved
                    medical devices and drugs and has performed hundreds of such analyses to date.
                    [60] The operations of ARIA are of particular significance when considering the
                    known limitations of the FDA’s Adverse Event Reporting System (FAERS), which the
                    FDA itself estimates to have received only one to ten percent of adverse events
                    that occur. [61]</para>
                <para>Although the Sentinel System has already provided measurable impact since its
                    implementation, it has some undesirable holes. The most notable one reveals the
                    limitations inherent to the data sources Sentinel accesses. The majority of
                    Sentinel’s data is derived from administrative claims data, which often lacks
                    the precision and accuracy required to perform sound analytics on health
                    outcomes. Claims data may diagnose and code conditions unreliably and often in
                    an oversimplified manner, a complication that is further confounded by the
                    prioritization of insurance coverage over medical precision. While a heart
                    attack may be diagnosed and billed accurately, outcomes like psychiatric side
                    effects, digestive problems, cognitive impairment, and countless others are
                    often reflected unreliably or not at all. [57]</para>
                <para>The data within the Sentinel System exhibits additional flaws. There is a
                    strong potential for selection bias, leading to unknown generalizability to
                    underrepresented populations, particularly those lacking health insurance. Even
                    among included individuals, data can vary. For example, follow-up times within
                    commercial health care plans are often shorter than those within Medicare and
                    Medicaid, making it difficult to perform parallel longitudinal studies. Data is
                    delivered to Sentinel quarterly or annually with a lag time of six to nine
                    months, limiting its usefulness when addressing rapidly developing situations
                    like COVID-19. Finally, data consistency and interoperability are additional
                    concerns, as data can vary in content, accessibility, and completeness across
                    the multiple data partners. [57] These functional gaps limit potential
                    applications of RWD, but once improved, the Sentinel System can further improve
                    as a powerful centralized tool for RWE generation, regulation, analytics,
                    research, and patient care. As with all applications of RWD, strategies for how
                    to best capture, maintain, and analyze RWD and RWE must continue to develop and
                    expand. </para>
            </section>
        </section>
    </section>
    <section>
        <title>Learnings</title>
        <para>EHRs have been in use in the U.S. since the 1970’s. However, the rush to implement
            EHRs nationwide did not occur until the introduction of the Meaningful Use (MU)
            incentive program in 2009. The EHR has provided a large pool of patient records and
            healthcare data from across the globe for secondary research. As of 2021, 85% of
            physicians in the US electronically recorded social determinants of health (SDOH) data
            and 97% electronically recorded broad determinants of health (BDOH) data. Rates of
            electronic recording of SDOH and BDOH data were slightly higher among primary care
            physicians, with 89% of primary care physicians electronically recording SDOH data and
            98% electronically recording BDOH data in 2021. [62] </para>
       <para>In the past, research relied upon billing data from the UB-04 and CMS-1500 billing
            forms as the source of structured data for research purposes. The UB-04 and CMS-1500
            billing forms are the standard claim forms that healthcare organization use for the
            billing of inpatient and outpatient, respectively, medical and mental health claims.
            [63-64] Although developed by CMS, the form has become the standard form used by all
            insurance carriers. This form captures data in a structured format and captures
            diagnoses, treatments and procedures, type of admission, medications, and demographic
            information. While the UB-04 and similar administrative data have been considered rich
            sources of data for research and can be readily de-identified, shared, and stored, much
            valuable information is lost because the coding systems used for billing purposes dilute
            data with non-specific coding systems that bundle similar conditions or procedures under
            the same code. This leads to various limitations when using current RWD that cannot be
            overlooked, ignored, or dismissed:</para>
        <para>
            <itemizedlist>
                <listitem>
                    <para>Data aggregated from multiple sources may impact the availability and
                        quality of data in real-time. </para>
                </listitem>
                <listitem>
                    <para>The time and effort to clean or harmonize data from multiple or disparate
                        sources increases time between the collection and availability of RWD for
                        researchers. This delay may further impact the accuracy or quality of
                        research data, meaning researchers are analyzing data no longer true of a
                        given scenario. </para>
                </listitem>
                <listitem>
                    <para>Patient reported data (information reported directly by patients to the
                        healthcare providers or researchers) provides a rich source of data for
                        researchers yet is challenging to collect and share due to a lack of data
                        standards and the various sources of patient reported data such as paper or
                        digital surveys, EHR portals, medical devices, or other sources.</para>
                </listitem>
                <listitem>
                    <para>Clinical documentation by nursing or allied health professionals is rarely
                        considered as a source of data for research. Yet, their documentation may
                        yield a rich source for data. Additionally, their documentation is more
                        likely to be captured in a structured manner in the form of structured (and
                        often researched and validated) assessments and flowsheets. </para>
                </listitem>
            </itemizedlist>
        </para>
        <para>Ideally RWD for RWE is extracted directly from clinical documentation. EHR
            vendor-agnostic data and interoperability standards such as Health Information Exchanges
            (HIEs), MU, HL7®, and FHIR® were created to encourage or mandate data interoperability
            across healthcare organizations. Yet healthcare organizations continue to consider their
            healthcare data as a proprietary asset. Adding complexity to this challenge is the
            inconsistent and/or proprietary nature of each EHR implementation to meet the needs and
            requests of the specific healthcare organization. This design and EHR implementation
            then impacts query methodology for secondary use of clinical data across healthcare
            systems and an overreliance on third party terminology vendors to provide the linkages
            between “provider-friendly” terminology and standardized clinical terminologies. These
            ‘provider friendly terms’ are often mapped to a broader than or inaccurate standardized
            language concept and insight to the quality of these mappings is opaque and error
            prone.</para>
        <para>To address this issue, research databases were created to allow researchers access to
            clinical data without actual access to the EHR. EHR database managers utilize “extract,
            transform, load” (ETL) to move data from EHR database(s) or other sources to a unified
            repository—typically a data warehouse. However, the ETL process relies on structured and
            standardized data. Much of the rich, useful data within a patient’s EMR is found beyond
            the reach of ETL. Narrative text with progress notes, diagnostic imaging and surgical
            reports, scanned PDF documents and free text fields contain a rich source of data to
            support RWE.</para>
        <para>Manual data curation and NLP are possible solutions to extract data from unstructured
            text. Manual data curation is a labor-intensive, time-consuming process involving human
            review of clinical documentation to read, interpret and extract information into a
            structured database. Well-defined heuristics and quality assurance processes are
            required to ensure accurate and consistent data extraction. Data available from data
            curation may not meet time-sensitive requirements due to the time and effort required
            for data extraction and any associated QA processes. NLP is a form of AI that can be
            used for computers to understand human generated language and process the data to
            understand the full meaning of the original intent. NLP combines algorithms with machine
            learning and models to correctly 16 extract and label data and assign meaning. Today,
            the most common models used to support NLP include convolutional neural networks (CNNs)
            and recurrent neural networks (RNNs). Yet, even the most well-defined data curation
            heuristics and processes may find clinician prose a challenge. Clinical findings with a
            diagnostic imaging or pathology report may not be expressed using explicit language. The
            actual clinical finding must be inferred from the clinical prose used by the provider in
            their report. Data curators or NLP may be challenged to interpret the actual clinical
            finding being described. Similarly, the presence or absence of a clinical finding may be
            hidden in the clinical prose as well.</para>
    </section>
</chapter>
